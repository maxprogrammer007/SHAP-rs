// src/traits/model.rs
use crate::core::{Dataset, Instance, Result, ShapError}; // Use our Dataset type and Result
use ndarray::Array1;

/// Trait for machine learning models that can be explained by SHAP.
///
/// This trait defines the interface required for a model to be used with
/// the SHAP explainers in this crate.
pub trait PredictModel {
    /// Predicts outputs for a batch of instances.
    ///
    /// # Arguments
    /// * `instances`: A `Dataset` (ndarray `Array2<f64>`) where each row is an instance
    ///   for which a prediction is required. These are often "perturbed" instances
    ///   generated by the SHAP algorithm (e.g., coalitions).
    ///
    /// # Returns
    /// * A `Result` containing an `Array1<f64>` of predictions.
    ///   - For regression models, this should be the direct output value for each instance.
    ///   - For classification models, this should be the probability (or log-odds,
    ///     depending on the explainer's needs and model's nature) of the class
    ///     being explained for each instance. The explainer might be configured
    ///     to explain a specific class.
    ///
    /// # Errors
    /// * Should return `ShapError::ModelPredictionError` if the model fails to predict.
    /// * Can also return `ShapError::IncompatibleDimensions` if the input `instances`
    ///   do not match the model's expected feature dimensions.
    fn predict(&self, instances: &Dataset) -> Result<Array1<f64>>;

    /// Returns the number of features the model expects.
    ///
    /// This is used by explainers to validate input and generate coalitions.
    fn num_features(&self) -> usize;

    // Optional: A method to indicate if the model output is probabilistic, log-odds, etc.
    // This could help explainers make better decisions or transformations.
    // fn output_type(&self) -> ModelOutputType; (e.g., enum { Probability, LogOdds, Raw })
}